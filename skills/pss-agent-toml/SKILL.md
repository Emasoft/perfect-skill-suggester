---
name: pss-agent-toml
description: "Build .agent.toml configuration profiles for Claude Code agents. Search, evaluate, and compare indexed elements (skills, agents, commands, rules, MCP, LSP). Add elements from local files, plugins, marketplaces, GitHub repos, or network paths. Collaborate with user or orchestrator to select the best-fit configuration."
argument-hint: "<agent-path> [--requirements PATH...]"
user-invocable: false
---

# PSS Agent TOML Profile Builder

## Overview

An `.agent.toml` file defines the complete configuration profile for a Claude Code agent: which skills it should use, which sub-agents complement it, which slash commands enhance its workflow, which rules constrain its behavior, which MCP servers extend its capabilities, and which LSP servers support its languages.

This skill teaches ANY agent or Claude model how to:
1. **Search** the element index to find candidates for each section
2. **Evaluate** candidates using scoring data, descriptions, and compatibility analysis
3. **Compare** alternatives side-by-side to resolve conflicts — including cross-type overlap detection
4. **Add** specific elements from any source (local, marketplace, GitHub, network)
5. **Validate coherence** — ensure no overlapping, conflicting, or redundant elements across ALL types
6. **Assemble** and validate the final `.agent.toml` file

**Default mode is autonomous**: the agent executes the full pipeline, produces the `.agent.toml`, and reports the result. Interactive collaboration with the user or orchestrator is optional and only happens when explicitly requested or when unresolvable conflicts are detected.

## Prerequisites

- **Skill index must exist**: `~/.claude/cache/skill-index.json` — run `/pss-reindex-skills` if missing
- **PSS Rust binary must be built**: Located at `$CLAUDE_PLUGIN_ROOT/rust/skill-suggester/bin/<platform>`
- **Agent definition file**: The `.md` file describing the agent to profile

---

## Quick Start

```bash
# Method A: Fully automated (no AI post-filtering)
uv run scripts/pss_generate_agent_toml.py /path/to/agent.md --validate

# Method B: With AI post-filtering (delegated to profiler agent)
/pss-setup-agent /path/to/agent.md --requirements /path/to/prd.md

# Method C: Manual assembly (full control, see detailed instructions below)
```

---

## The .agent.toml Format

Every `.agent.toml` has these sections:

```toml
# Auto-generated by PSS
# Agent: <name>
# Generated: <timestamp>

[agent]                    # REQUIRED: Agent identification
name = "my-agent"          # kebab-case, matches ^[a-z0-9][a-z0-9_-]*$
source = "path"            # "path" or "plugin:<name>"
path = "/abs/path/to/my-agent.md"

[requirements]             # OPTIONAL: Project context used for profiling
files = ["prd.md"]         # Basenames of requirement files
project_type = "web-app"   # web-app, cli-tool, mobile-app, library, api, microservice
tech_stack = ["typescript", "react", "postgresql"]

[skills]                   # REQUIRED: Tiered skill recommendations
primary = ["skill-a", "skill-b"]        # Max 7 — core daily-use skills (score >= 60%)
secondary = ["skill-c", "skill-d"]      # Max 12 — useful common tasks (score 30-59%)
specialized = ["skill-e"]               # Max 8 — niche situations (score 15-29%)

[skills.excluded]          # OPTIONAL: Transparency — why certain skills were rejected
# "vue-frontend" = "Conflicts with React (requirements specify React)"
# "jest-testing" = "Vitest preferred for Vite-based project"

[agents]                   # OPTIONAL: Complementary sub-agents
recommended = ["sleuth", "e2e-tester"]

[commands]                 # OPTIONAL: Recommended slash commands
recommended = ["commit", "describe-pr"]

[rules]                    # OPTIONAL: Enforcement rules
recommended = ["claim-verification", "observe-before-editing"]

[mcp]                      # OPTIONAL: MCP servers for extended capabilities
recommended = ["chrome-devtools"]

[hooks]                    # OPTIONAL: Hook configurations
recommended = []

[lsp]                      # OPTIONAL: Language servers (assigned by language detection)
recommended = ["typescript-lsp", "pyright-lsp"]
```

**Schema reference**: `$CLAUDE_PLUGIN_ROOT/schemas/pss-agent-toml-schema.json`
**Validator**: `uv run scripts/pss_validate_agent_toml.py <file> --check-index --verbose`

---

## Step-by-Step Profile Building Process

### Phase 1: Gather Context

**1.1 Read the agent definition file**

Read the agent's `.md` file completely. Extract:
- **name**: From YAML frontmatter `name:` field or filename stem
- **description**: From frontmatter `description:` or first non-heading paragraph
- **role**: developer, tester, reviewer, deployer, designer, security, data-scientist
- **duties**: From bullet lists under headings containing "responsibilities", "duties", "tasks"
- **tools**: From frontmatter `tools:` / `allowed-tools:` or tool mentions in body
- **domains**: From frontmatter or inferred (security, frontend, backend, devops, data, etc.)

**1.2 Read requirements documents** (if available)

Read all provided design/requirements files. Extract:
- **project_type**: What is being built (web-app, mobile-app, cli-tool, library, etc.)
- **tech_stack**: Specific technologies, frameworks, languages
- **key features**: Core capabilities the project needs
- **constraints**: Performance, compliance, platform targets

**1.3 Detect project languages from cwd**

Scan the working directory for:
- `package.json` / `tsconfig.json` → TypeScript/JavaScript
- `pyproject.toml` / `setup.py` → Python
- `Cargo.toml` → Rust
- `go.mod` → Go
- `*.swift` / `Package.swift` → Swift
- `pom.xml` / `build.gradle` → Java
- `CMakeLists.txt` → C/C++

This determines LSP server assignment.

---

### Phase 2: Get Candidates from the Index

**2.1 Automated scoring (Rust binary)**

Build a JSON descriptor and invoke the binary:

```bash
# Create descriptor file
cat > /tmp/pss-agent-profile-input.json << 'EOF'
{
  "name": "<agent-name>",
  "description": "<agent description + requirements summary>",
  "role": "<role>",
  "duties": ["<duty1>", "<duty2>"],
  "tools": ["<tool1>", "<tool2>"],
  "domains": ["<domain1>", "<domain2>"],
  "requirements_summary": "<condensed requirements text, max 2000 chars>",
  "cwd": "<absolute path to working directory>"
}
EOF

# Invoke binary
"$BINARY_PATH" --agent-profile /tmp/pss-agent-profile-input.json --format json --top 30
```

The binary returns scored candidates grouped by type:
```json
{
  "agent": "name",
  "skills": {
    "primary": [{"name":"...", "score":0.85, "confidence":"HIGH", "evidence":["keyword:docker"], "description":"..."}],
    "secondary": [...],
    "specialized": [...]
  },
  "complementary_agents": ["agent-x"],
  "commands": [{"name":"...", "score":0.6, ...}],
  "rules": [{"name":"...", "score":0.5, ...}],
  "mcp": [{"name":"...", "score":0.4, ...}],
  "lsp": [{"name":"...", "score":0.3, ...}]
}
```

**2.2 Manual search (for finding specific capabilities)**

If the binary output doesn't cover a known need, search the index directly:

```bash
# Search by keyword across all element types
cat ~/.claude/cache/skill-index.json | python3 -c "
import json, sys
idx = json.load(sys.stdin)
query = sys.argv[1].lower()
for name, entry in idx['skills'].items():
    kws = ' '.join(entry.get('keywords', []))
    desc = entry.get('description', '')
    if query in kws.lower() or query in desc.lower() or query in name.lower():
        print(f'{entry.get(\"type\",\"skill\"):8} {name:30} {desc[:60]}')
" "<search-term>"

# Search by type
cat ~/.claude/cache/skill-index.json | python3 -c "
import json, sys
idx = json.load(sys.stdin)
target_type = sys.argv[1]
for name, entry in idx['skills'].items():
    if entry.get('type') == target_type:
        print(f'{name:30} {entry.get(\"description\",\"\")[:80]}')
" "<type>"  # skill, agent, command, rule, mcp, lsp
```

---

### Phase 3: Evaluate and Compare Candidates

**3.1 Present candidates to the user/orchestrator**

For each section, present candidates in a comparison table:

```
SKILLS — Primary Candidates (max 7):
| # | Name               | Score | Confidence | Evidence                    | Description                          |
|---|--------------------| ------| ----------|-----------------------------| -------------------------------------|
| 1 | building-with-bun  | 0.92  | HIGH      | keyword:bun, intent:build   | Build JS/TS projects using Bun       |
| 2 | exhaustive-testing | 0.85  | HIGH      | keyword:test, intent:test   | Write comprehensive test coverage    |
| 3 | tdd                | 0.78  | HIGH      | keyword:test, co_usage:...  | Test-driven development workflow     |
```

**3.2 Detect conflicts and alternatives**

Check for mutually exclusive elements:
- **Framework conflicts**: React vs Vue vs Angular vs Svelte
- **Runtime conflicts**: Deno vs Node vs Bun
- **ORM conflicts**: Prisma vs TypeORM vs Drizzle
- **Testing conflicts**: Jest vs Vitest vs Mocha
- **State management**: Redux vs Zustand vs MobX

When conflicts are detected, present them explicitly:
```
CONFLICT DETECTED: Testing framework
  Option A: jest-testing (score: 0.72) — Jest for Node.js
  Option B: vitest-testing (score: 0.68) — Vitest for Vite projects
  Recommendation: Option B (requirements specify Vite)
  → Awaiting user/orchestrator decision
```

**3.3 Check compatibility**

For each candidate, verify:
- Language/runtime compatibility with tech_stack
- Framework compatibility with project requirements
- Domain relevance to the agent's role
- No obsolete/deprecated elements

**3.4 Identify gaps**

After reviewing binary output, check if requirements mention needs not covered:
- "real-time" → need WebSocket/SSE skills?
- "i18n" → need internationalization skills?
- "HIPAA" / "PCI" → need compliance/security skills?
- "PDF generation" → need document processing skills?

Report gaps to user/orchestrator for resolution.

---

### Phase 4: Add Elements from External Sources

The user or orchestrator may request adding specific elements not in the current index. These can come from ANY source:

**4.1 From a local file or folder**

```
User: "Add the skill at /path/to/my-custom-skill/SKILL.md"
```

Action:
1. Read the file at the specified path
2. Extract name, description, keywords from frontmatter/content
3. Verify it's a valid element file (has proper structure)
4. Add the element's name to the appropriate section in `.agent.toml`
5. Record the path in a comment for traceability

```toml
[skills]
# Custom local skill added by user request
primary = ["my-custom-skill", "building-with-bun", ...]
```

**4.2 From an installed plugin**

```
User: "Add the agent from the multi-platform-apps plugin"
```

Action:
1. Search plugin cache: `~/.claude/plugins/cache/*/multi-platform-apps/*/agents/*.md`
2. Also check: `~/.claude/plugins/multi-platform-apps/agents/*.md`
3. List available agents from that plugin
4. Present to user for selection
5. Add selected agent(s) to `.agent.toml`

**4.3 From a marketplace plugin (not installed)**

```
User: "Add skills from the claude-plugins-validation plugin on the marketplace"
```

Action:
1. Search the marketplace: `gh api repos/<marketplace-owner>/claude-plugins-marketplace/contents/plugins`
2. Or fetch the plugin manifest: `gh api repos/<owner>/<repo>/contents/.claude-plugin/plugin.json`
3. Parse the manifest to find available skills, agents, commands
4. Present the list to user for selection
5. Add selected elements to `.agent.toml` with `source = "plugin:<name>"`
6. Note: The plugin must be installed for the agent to actually USE these elements at runtime

**4.4 From a GitHub/git repository URL**

```
User: "Add the security skill from https://github.com/user/repo"
```

Action:
1. Fetch the repo contents: `gh api repos/<owner>/<repo>/contents/skills` or `/agents`
2. Or clone to temp: `git clone --depth 1 <url> /tmp/pss-fetch-<hash>`
3. Find `.md` files in standard locations (skills/, agents/, commands/, rules/)
4. Extract metadata from each file
5. Present to user for selection
6. Add selected elements with a comment noting the source URL

```toml
[skills]
# From https://github.com/user/repo (not installed — install plugin first)
primary = ["remote-security-skill", ...]
```

**4.5 From a network shared folder**

```
User: "Add agents from /mnt/shared/team-agents/"
```

Action:
1. List `.md` files in the specified directory
2. Read each, extract metadata (name, description, type)
3. Present to user for selection
4. Add selected elements to `.agent.toml`
5. Note: The agent.md file must be accessible at runtime for the agent to load it

**4.6 From a URL to a raw file**

```
User: "Add the skill at https://raw.githubusercontent.com/user/repo/main/skills/my-skill/SKILL.md"
```

Action:
1. Fetch the file content via `curl` or WebFetch
2. Extract metadata from the content
3. Add to `.agent.toml` after user confirmation

---

### Phase 5: Cross-Type Coherence Validation

**This is the most critical phase.** The Rust binary scores candidates within each type independently. But it does NOT check for overlaps or conflicts BETWEEN types. You MUST validate coherence across ALL sections before finalizing.

**5.1 Cross-type overlap detection**

Compare every element in the profile against every other element across ALL types. Look for:

**Skill ↔ MCP overlap**: A skill and an MCP server that provide the same capability.
- Example: A "chrome-devtools" skill AND a "chrome-devtools" MCP server — the MCP server provides the actual tools, the skill provides instructions. Both are valid (keep both).
- Example: A "database-management" skill AND a "postgres-mcp" MCP server — the MCP gives direct DB access, making parts of the skill redundant. Keep the MCP, demote the skill to specialized or remove.

**Skill ↔ Agent overlap**: A skill that teaches the same thing an agent does.
- Example: A "python-test-writer" skill AND a "python-test-writer" agent — the agent IS the skill executor. Keep the agent, remove the skill (the agent already loads its own skills).
- Example: A "security" skill AND an "aegis" agent — different scope, both valid.

**Agent ↔ Agent overlap**: Two agents with the same capabilities.
- Example: "sleuth" agent AND "debug-agent" — both do debugging. Keep ONE based on which better matches the project. Document the other in `[skills.excluded]`.

**Skill ↔ Command overlap**: A skill that automates what a command does manually.
- Generally keep both — commands are user-invoked, skills are auto-suggested. But flag if a skill's ONLY purpose is to invoke the command.

**MCP ↔ MCP overlap**: Two MCP servers providing the same tools.
- Example: Two different browser automation MCPs — keep the one that matches the project's existing config.

**Rule ↔ Rule conflict**: Two rules that contradict each other.
- Example: A "always-use-mocks" rule AND a "never-use-mocks" rule. Remove the one that contradicts the project's testing philosophy.

**5.2 Coherence checklist**

Before writing the final `.agent.toml`, verify ALL of these:

- [ ] No skill duplicates the capability of an MCP server already in `[mcp]`
- [ ] No skill duplicates the capability of an agent already in `[agents]`
- [ ] No two agents in `[agents]` serve the same role
- [ ] No two MCP servers in `[mcp]` provide overlapping tool sets
- [ ] No two rules in `[rules]` contradict each other
- [ ] No skill in primary tier is a strict subset of another primary skill
- [ ] Every command in `[commands]` is relevant to the agent's actual workflow
- [ ] Every rule in `[rules]` applies to the agent's domain (not a different domain)
- [ ] LSP servers match the project's actual languages (not guessed)
- [ ] Framework-specific elements all target the SAME framework (no React + Vue mix)
- [ ] Runtime-specific elements all target the SAME runtime (no Node + Deno mix)

**5.3 Resolution strategy**

When an overlap or conflict is found:
1. **Read both elements' descriptions/SKILL.md** to understand exact scope
2. **Determine which provides more value** for this specific agent+project combination
3. **Keep the higher-value element**, remove or demote the other
4. **Document the exclusion** in `[skills.excluded]` with the reason
5. If truly undecidable (both equally valuable, different trade-offs), **ask the user/orchestrator** — but only in this case

**5.4 Autonomous vs Interactive mode**

**Autonomous (default)**: Execute the full pipeline, apply coherence validation automatically, resolve conflicts using the rules above, produce the final `.agent.toml`, and report the result. Only surface unresolvable conflicts to the user.

**Interactive (when requested)**: Present the draft profile with a comparison table, accept modifications (add/remove/move/replace elements), re-validate after each change, and confirm before writing.

The interactive mode activates when:
- The user explicitly asks for review ("let me review the profile first")
- An orchestrator requests collaboration ("present options for approval")
- Unresolvable conflicts are detected (truly equal alternatives with no deciding factor)

---

## Method A: Automated Script

The fastest path — runs the full pipeline mechanically without AI post-filtering:

```bash
# Basic: generate from agent.md
uv run scripts/pss_generate_agent_toml.py /path/to/agent.md --validate

# With requirements context
uv run scripts/pss_generate_agent_toml.py /path/to/agent.md \
  --requirements /path/to/prd.md /path/to/tech-spec.md \
  --validate

# Custom output path
uv run scripts/pss_generate_agent_toml.py /path/to/agent.md \
  --output /custom/path/my-agent.agent.toml \
  --validate

# Dry-run: see the JSON descriptor without calling binary
uv run scripts/pss_generate_agent_toml.py /path/to/agent.md --dry-run

# With explicit binary and index paths
uv run scripts/pss_generate_agent_toml.py /path/to/agent.md \
  --binary /path/to/pss-darwin-arm64 \
  --index /path/to/skill-index.json \
  --validate
```

**Flags:**
| Flag | Description | Default |
|------|-------------|---------|
| `--requirements` | Space-separated paths to design docs | None |
| `--output` | Output .agent.toml path | `team/agents-cfg/<name>.agent.toml` |
| `--binary` | Explicit PSS binary path | Auto-detect from CLAUDE_PLUGIN_ROOT |
| `--index` | Path to skill-index.json | `~/.claude/cache/skill-index.json` |
| `--cwd` | Working directory for context | `os.getcwd()` |
| `--validate` | Run validator after writing | Off |
| `--dry-run` | Print JSON descriptor, don't call binary | Off |

**When to use Method A:**
- Quick generation without human review
- CI/CD pipelines
- Batch generation for multiple agents
- When the binary scoring is sufficient (no complex conflicts)

---

## Method B: Slash Command (Delegated to Profiler Agent)

Spawns an AI agent that adds intelligent post-filtering:

```
/pss-setup-agent /path/to/agent.md
/pss-setup-agent /path/to/agent.md --requirements /path/to/prd.md
/pss-setup-agent plugin-name:agent-name
```

**When to use Method B:**
- When you need mutual exclusivity detection (framework/runtime conflicts)
- When requirements are complex and need nuanced evaluation
- When you want obsolescence/deprecation checking via WebSearch
- When you want AI-driven gap analysis

**The profiler agent workflow:**
1. Reads agent + requirements (same as Method A)
2. Calls Rust binary (same as Method A)
3. **AI post-filtering** (unique to Method B):
   - Reads each candidate's SKILL.md file
   - Detects mutual exclusivity (React vs Vue, Jest vs Vitest, etc.)
   - Checks for obsolete/deprecated elements
   - Verifies stack compatibility
   - Promotes under-scored elements that requirements explicitly need
   - Prunes redundant elements (strict subsets)
4. Writes and validates `.agent.toml`

---

## Method C: Manual Assembly

For full control — follow these steps to build `.agent.toml` by hand.

### C.1 Create the descriptor JSON

```json
{
  "name": "my-agent",
  "description": "A security-focused backend developer for Python microservices",
  "role": "developer",
  "duties": [
    "Write secure Python microservices",
    "Implement API endpoints with FastAPI",
    "Review code for security vulnerabilities",
    "Write integration tests"
  ],
  "tools": ["Bash", "Read", "Write", "Edit", "Grep", "Glob", "WebSearch"],
  "domains": ["security", "backend", "python"],
  "requirements_summary": "Python 3.12 FastAPI microservices with PostgreSQL, Redis caching, JWT auth, deployed on AWS ECS",
  "cwd": "/path/to/project"
}
```

### C.2 Invoke the binary

```bash
/path/to/pss-binary --agent-profile /tmp/descriptor.json --format json --top 30
```

### C.3 Parse the output

The JSON output contains scored candidates. Extract names from each section.

### C.4 Write the TOML

Use the template from "The .agent.toml Format" section above. Populate each section from the binary output.

### C.5 Add custom elements

Manually add any elements not in the index (from local files, repos, etc.) to the appropriate sections.

### C.6 Validate

```bash
uv run scripts/pss_validate_agent_toml.py my-agent.agent.toml --check-index --verbose
```

Exit codes: 0 = valid, 1 = errors found, 2 = TOML parse error.

---

## AI Post-Filtering Guide

For agents applying intelligent filtering (Method B or manual):

### Mutual Exclusivity Detection

These element families are mutually exclusive — only ONE from each group:

| Category | Alternatives |
|----------|-------------|
| JS Framework | React, Vue, Angular, Svelte, Solid |
| JS Runtime | Node, Deno, Bun |
| JS Bundler | Webpack, Vite, esbuild, Parcel, Turbopack |
| CSS Framework | Tailwind, Bootstrap, Bulma, Chakra UI |
| ORM | Prisma, TypeORM, Drizzle, Sequelize |
| Testing | Jest, Vitest, Mocha, Jasmine |
| State Mgmt | Redux, Zustand, MobX, Recoil, Jotai |
| Deployment | Vercel, Netlify, AWS, GCP, Azure |
| Python Web | Django, Flask, FastAPI, Starlette |
| Python Test | pytest, unittest, nose2 |
| Mobile | React Native, Flutter, SwiftUI, Kotlin Compose |

**Resolution rule**: Keep the one that matches the tech_stack in requirements. If no requirements, keep the highest-scored and document alternatives in `[skills.excluded]`.

### Obsolescence Check

Flag elements that reference:
- Deprecated APIs or patterns (componentWillMount, var, require() in ESM)
- End-of-life runtimes (Python 2, Node 14)
- Superseded tools (TSLint → ESLint, Moment.js → Luxon/date-fns)

Use WebSearch to verify: "Is <library> deprecated in 2026?"

### Stack Compatibility

Verify each candidate matches the project:
- Python-only skill for a TypeScript project → REMOVE
- iOS skill for a web-only project → REMOVE
- React skill when requirements specify Vue → REMOVE

### Redundancy Pruning

If skill A covers everything skill B does plus more, remove skill B. Example: `exhaustive-testing` subsumes `unit-testing` — keep only `exhaustive-testing`.

---

## Scoring Reference

The Rust binary uses weighted scoring:

| Evidence Type | Weight | Description |
|--------------|--------|-------------|
| `keyword` | +2 | Direct keyword match |
| `intent` | +4 | Intent category match |
| `pattern` | +3 | Regex pattern match |
| `directory` | +5 | Working directory match |
| `path` | +4 | File path pattern match |
| `first_match` | +10 | First match bonus |
| `original_bonus` | +3 | Match on original (uncorrected) query |

**Tier thresholds** (relative to max score):
- **Primary** (max 7): score >= 60% of maximum
- **Secondary** (max 12): score 30-59% of maximum
- **Specialized** (max 8): score 15-29% of maximum

**Tier boost** in scoring:
- `primary`: +5 points
- `secondary`: +0 points (default)
- `specialized`: -2 points

---

## Troubleshooting

| Problem | Solution |
|---------|----------|
| "Skill index not found" | Run `/pss-reindex-skills` to build the index |
| "Binary not found" | Build with `cd rust/skill-suggester && cargo build --release` |
| "Unsupported platform" | Check `platform.system()` and `platform.machine()` match PLATFORM_MAP |
| "TOML validation failed" | Read validator errors — common: missing quotes, duplicate skills across tiers |
| "No candidates returned" | Agent description too vague — add more specific duties and domains |
| "All candidates low confidence" | Requirements may not match any indexed keywords — try more specific terms |
| Empty `[commands]` or `[rules]` | These types may not be indexed yet — run `/pss-reindex-skills` |
| "Unknown section" warning | Validator may be out of date — update `OPTIONAL_SECTIONS` in validator script |

---

## Complete Example

**Input**: Profile a "frontend-developer" agent for a React/Next.js e-commerce project.

**Agent file** (`agents/frontend-developer.md`):
```markdown
---
name: frontend-developer
description: Build React components, implement responsive layouts, and handle client-side state management
tools: [Bash, Read, Write, Edit, Grep, Glob, WebSearch, WebFetch, Task]
---
# Frontend Developer
Builds UI components, manages state, handles routing and data fetching.
```

**Requirements** (`prd.md`): "E-commerce platform with React 19, Next.js 15, Tailwind CSS, PostgreSQL, Stripe payments, i18n support."

**Command**:
```bash
uv run scripts/pss_generate_agent_toml.py agents/frontend-developer.md \
  --requirements prd.md \
  --validate
```

**Output** (`team/agents-cfg/frontend-developer.agent.toml`):
```toml
# Auto-generated by pss_generate_agent_toml.py
# Agent: frontend-developer
# Generated: 2026-02-27T10:30:00+00:00
# Requirements: prd.md

[agent]
name = "frontend-developer"
source = "path"
path = "/abs/path/to/agents/frontend-developer.md"

[requirements]
files = ["prd.md"]
project_type = "web-app"
tech_stack = ["react", "nextjs", "tailwind", "postgresql", "stripe"]

[skills]
primary = ["building-with-bun", "css-to-svg-conversion", "development-standards"]
secondary = ["exhaustive-testing", "handle-deprecation-warnings", "dependency-management", "git-workflow"]
specialized = ["accessibility-compliance", "responsive-design"]

[agents]
recommended = ["ui-ux-designer", "e2e-tester"]

[commands]
recommended = ["commit", "describe-pr"]

[rules]
recommended = ["claim-verification", "observe-before-editing"]

[mcp]
recommended = ["chrome-devtools"]

[hooks]
recommended = []

[lsp]
recommended = ["typescript-lsp"]
```
